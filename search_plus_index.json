{"./":{"url":"./","title":"Introduction","keywords":"","body":"简介 本书主要介绍了运维相关的知识，包括了云计算、容器、linux知识的学习记录，已经在使用的过程中遇到的一些问题及解决方案，后续会逐步完善，希望这些笔记在大家学习的过程能帮到大家。 © vishon all right reserved，powered by GitbookUpdated at 2021-05-20 17:58:23 "},"gitbook/本地机器安装gitbook.html":{"url":"gitbook/本地机器安装gitbook.html","title":"本地机器安装gitbook","keywords":"","body":"gitbook简介 gitbook网站是一个简单的个人在线书籍网站，在这里可以把自己的文档整理成书籍发布出来，便于阅读。 gitbook网站：https://legacy.gitbook.com/ 本文主要讲解在gitbook网站上发布一个书籍文档和使用gitbook提供的工具在本地开发一个书籍文档部署到自己的服务上 在此之前你需要会如下准备： 账号： github有账号，gitbook使用github账号注册 git：代码管理工具 Markdown：gitbook主要使用MD语法来编写书籍的 gitbook工具：如果你在本地开发需要安装此插件，下面有介绍 nodejs环境：gitbook插件需要的运行环境 一款Markdown编辑器：方便本地开发，推荐Typora或gitbook自己的编辑器gitbook editor 安装nodejs环境 本次操作都在windows系统上进行操作，nodejs的安装具体可以参考文档https://www.runoob.com/nodejs/nodejs-install-setup.html 安装gitbook npm install gitbook-cli -g 初始化gitbook 创建一个文件夹gitbook，然后初始化gitbook，最后运行gitbook # mkdir gitbook # cd gitbook # gitbook init # gitbook serve 运行后会在启动一个服务，可以在浏览器输入localhost:4000，这样就可以访问gitbook了 © vishon all right reserved，powered by GitbookUpdated at 2021-05-19 20:00:58 "},"gitbook/gitbook添加笔记.html":{"url":"gitbook/gitbook添加笔记.html","title":"gitbook添加笔记","keywords":"","body":"我们讲下如何在gitbook中添加笔记，gitbook初始化之后默认会创建SUMMARY.md和README.md这2个文件 README.md里面的内容是你这本书的简介部分 # 简介 本书主要介绍了一些k8s的相关操作,运维知识的学习和讲解，test SUMMARY.md文件主要是用来添加文章目录 # Summary - [简介](README.md) ### 如何搭建属于自己的gitbook ### linux运维笔记 - [腾讯云cvm上搭建openvpn](linux/2021-03-25-Build-openvpn-intranet-access-vpc-on-cvm.md) ### docker运维笔记 - [1](docker/1.md) ### kubernetes运维笔记 - [强制删除Terminating状态ns](k8s/强制删除Terminating状态ns.md) ### TKE运维笔记 - [1](tke/1.md) - [2](tke/2.md) 如果你需要添加笔记，可以先创建文件夹，存放你编写的markdown笔记，然后再SUMMARY.md配置上目录即可。 © vishon all right reserved，powered by GitbookUpdated at 2021-05-19 20:07:36 "},"gitbook/gitbook上传到github托管.html":{"url":"gitbook/gitbook上传到github托管.html","title":"gitbook上传到github托管","keywords":"","body":"github创建代码分支 这里我们创建了一个mybook的代码仓库用来存放gitbook 编译gitbook为静态文件 # cd gitbook # mkdir content 然后将所有的md文件拷贝到content目录下，然后我们运行gitbook gitbook serve ./content ./gh-pages 这样会自动创建 gh-pages 文件夹，文件夹中的内容，就是编译后的输出。 编写自动化脚本部署gitbook 自动化创建和更新 gh-pages 所以，我们采用一个 npm 包，来帮助我们完成上面的操作 cd gitbook/ npm i gh-pages 然后创建 gitbook/scripts/deploy-gh-pages.js 里面的内容是： 'use strict'; var ghpages = require('gh-pages'); main(); function main() { ghpages.publish('./gh-pages', console.error.bind(console)); } 上面的脚本的作用，就是把当前文件夹下的 gh-pages 文件夹中的所有内容，push 到本仓库的 gh-pages 分支。 然后添加几个 npm 脚本 deploy （ deploy 就是部署的意思），还有 build （意思是编译），还有 publish（意思是发布），如下： \"scripts\": { \"start\": \"gitbook serve ./content ./gh-pages\", \"build\": \"gitbook build ./content ./gh-pages\", \"deploy\": \"node ./scripts/deploy-gh-pages.js\", \"publish\": \"npm run build&&npm run deploy\" }, 这样，以后我修改了书稿，只需运行 npm run publish 如果命令返回 undefined 字样，表示没有出现错误，部署成功。 就可以把最新的书稿 push 到远端仓库的 gh-pages 分支了。 配置github page 进入仓库，选择settings选项，找到page选项，配置下GitHub Pages，这里我之前配置了我自己的域名到github，所以我这边显示的自定义域名，而不是github.io这个 通过域名访问gitbook 浏览器输入https://www.niewx.cn/mybook，就可以查看gitbook了 © vishon all right reserved，powered by GitbookUpdated at 2021-05-19 20:21:53 "},"gitbook/gitbook插件使用.html":{"url":"gitbook/gitbook插件使用.html","title":"gitbook插件使用","keywords":"","body":"配置gitbook插件 gitbook默认只有一些插件，其他插件需要自己安装，安装插件很简单，在content目录下配置一个book.json即可 { \"title\": \"运维操作指南\", \"description\": \"运维操作指南\", \"author\": \"vishon\", \"gitbook\": \">= 3.2.2\", \"language\": \"zh-hans\", \"links\": { \"sidebar\": { \"聂伟星个人博客\": \"https://www.niewx.cn\", \"TKE运维手册\": \"https://cloud.tencent.com/developer/column/87421\" } }, \"plugins\": [ \"github\", \"editlink\", \"-lunr\", \"-search\", \"search-plus\", \"tbfed-pagefooter\", \"splitter\", \"page-toc-button\", \"back-to-top-button\", \"-lunr\", \"-search\", \"search-plus\", \"github-buttons@2.1.0\", \"favicon@^0.0.2\", \"3-ba\", \"disqus\", \"theme-default\", \"pageview-count\", \"auto-scroll-table\", \"popup\", \"code\", \"-highlight\", \"prism\", \"prism-themes\" ], \"pdf\": { \"toc\": true, \"pageNumbers\": true, \"fontSize\": 11 }, \"pluginsConfig\": { \"github\": { \"url\": \"https://github.com/nieweixing\" }, \"editlink\": { \"base\": \"https://github.com/nieweixing/mybook/tree/gh-pages\", \"label\": \"编辑本页\" }, \"tbfed-pagefooter\": { \"copyright\":\"&copy vishon\", \"modify_label\": \"Updated at\", \"modify_format\": \"YYYY-MM-DD HH:mm:ss\" }, \"image-captions\": { \"caption\": \"图片 - _CAPTION_\" }, \"github-buttons\": { \"repo\": \"nieweixing/mybook\", \"types\": [\"star\"], \"size\": \"small\" }, \"favicon\": { \"shortcut\": \"favicon.ico\", \"bookmark\": \"favicon.ico\" }, \"disqus\": { \"shortName\": \"nieweixing-github-io\" }, \"3-ba\": { \"token\": \"c03bec8e82bc53c064e0e648ffa54d88\" }, \"code\": { \"copyButtons\": true }, \"prism\": { \"css\": [ \"prismjs/themes/prism-okaidia.css\" ] } }, \"generator\": \"site\" } 配置好之后，需要执行npm install安装下插件，安装完成后会将插件放在node_modules目录，这里如果下载插件很慢，可以直接到我的github目录下拷贝对应的包https://github.com/nieweixing/mybook/tree/gh-pages/gitbook gitbook install ./content 配置discuss评论系统 这里可以给gitbook配置disscus评论系统 注册 disqus账号 https://disqus.com/ 右上角 Setting --> Add Disqus To Site --> 最下面 GET STARTED --> I want to install ... 填写网站 name 和分类 --> Create Site 填写 Website URL如 https://www.niewx.cn/mybook 配置好之后再book.json的disqus字段配置你创建的shortname，最后在gitbook目录下执行发布命令发布到github，这样我们就可以使用discuss评论功能了 gitbook插件列表 mygitalk 基于gitalk的评论插件 ➡️ https://github.com/snowdreams1006/gitbook-plugin-mygitalk theme-default GitBook的默认主题 ➡️ https://github.com/GitbookIO/theme-default autotheme 自动换肤插件 ➡️ https://github.com/willin/gitbook-plugin-autotheme sharing 默认的分享插件 ➡️ https://github.com/GitbookIO/plugin-sharing fontsettings 默认的字体、字号、颜色设置插件 ➡️ https://github.com/GitbookIO/plugin-fontsettings highlight 默认的代码高亮插件，通常会使用 prism 来替换 ➡️ https://github.com/GitbookIO/plugin-highlight search 默认搜索插件 ➡️ https://github.com/GitbookIO/plugin-search search-plus 支持中文搜索插件 ➡️ https://github.com/lwdgit/gitbook-plugin-search-plus prism 基于 Prism 的代码高亮 ➡️ https://github.com/gaearon/gitbook-plugin-prism favicon 更改网站的 favicon.ico ➡️ https://github.com/menduo/gitbook-plugin-favicon github 在右上角显示 github 仓库的图标链接 ➡️ https://github.com/GitbookIO/plugin-github github-buttons 显示 github 仓库的star和fork按钮 ➡️ https://github.com/azu/gitbook-plugin-github-buttons splitter 在左侧目录和右侧内容之间添加一个可以拖拽的栏，用来调整两边的宽度 ➡️ https://github.com/yoshidax/gitbook-plugin-splitter copy-code-button 为代码块添加复制的按钮 ➡️ https://github.com/WebEngage/gitbook-plugin-copy-code-button tbfed-pagefooter 自定义页脚，显示版权和最后修订时间 ➡️ https://github.com/zhj3618/gitbook-plugin-tbfed-pagefooter expandable-chapters 收起或展开章节目录中的父节点 ➡️ https://github.com/DomainDrivenArchitecture/gitbook-plugin-expandable-chapters expandable-chapters-small 比较好的折叠侧边栏 ➡️ https://github.com/lookdczar/gitbook-plugin-expandable-chapters-small-auto book-summary-scroll-position-saver 自动保存左侧目录区域导航条的位置 ➡️ https://github.com/yoshidax/gitbook-plugin-book-summary-scroll-position-saver ga 添加 Google 统计代码 ➡️ https://github.com/GitbookIO/plugin-ga sitemap 生成站点地图 ➡️ https://github.com/GitbookIO/plugin-sitemap baidu 使用百度统计 ➡️ https://github.com/poppinlp/gitbook-plugin-baidu Donate Gitbook 捐赠打赏插件 ➡️ https://github.com/willin/gitbook-plugin-donate anchors 标题带有 github 样式的锚点 ➡️ https://github.com/rlmv/gitbook-plugin-anchors anchor-navigation-ex 插件锚导航-EX ➡️ https://github.com/zq99299/gitbook-plugin-anchor-navigation-ex theme-api 编写 API 文档 ➡️ https://github.com/GitbookIO/theme-api katex 使用KaTex进行数学排版 ➡️ https://github.com/GitbookIO/plugin-katex editlink 内容顶部显示编辑本页链接 ➡️ https://github.com/zhaoda/gitbook-plugin-editlink ad 在每个页面顶部和底部添加广告或任何自定义内容 ➡️ https://github.com/zhaoda/gitbook-plugin-ad image-captions 抓取内容中图片的alt或title属性，在图片下面显示标题 ➡️ https://github.com/todvora/gitbook-plugin-image-captions chart 使用 C3.js 图表 ➡️ https://github.com/csbun/gitbook-plugin-chart styles-sass 使用 SASS 替换 CSS ➡️ https://github.com/GitbookIO/plugin-styles-sass styles-less 使用 LESS 替换 CSS ➡️ https://github.com/GitbookIO/plugin-styles-less disqus 添加 disqus 评论插件 ➡️ https://github.com/GitbookIO/plugin-disqus latex-codecogs 使用数学方程式 ➡️ https://github.com/GitbookIO/plugin-latex-codecogs mermaid 使用流程图 ➡️ https://github.com/JozoVilcek/gitbook-plugin-mermaid atoc 插入 TOC 目录 ➡️ https://github.com/willin/gitbook-plugin-atoc ace 插入代码高亮编辑器 ➡️ https://github.com/ymcatar/gitbook-plugin-ace sectionx 分离各个段落，并提供一个展开收起的按钮 ➡️ https://github.com/ymcatar/gitbook-plugin-sectionx mcqx 交互式多选插件 ➡️ https://github.com/ymcatar/gitbook-plugin-mcqx include-codeblock 通过引用文件插入代码 ➡️ https://github.com/azu/gitbook-plugin-include-codeblock fbqx 使用填空题 ➡️ https://github.com/Erwin-Chan/gitbook-plugin-fbqx spoiler 隐藏答案，当鼠标划过时才显示 ➡️ https://github.com/ymcatar/gitbook-plugin-spoiler anchor-navigation 锚点导航 ➡️ https://github.com/yaneryou/gitbook-plugin-anchor-navigation youtubex 插入 YouTube 视频 ➡️ https://github.com/ymcatar/gitbook-plugin-youtubex redirect 重定向页面跳转 ➡️ https://github.com/ketan/gitbook-plugin-redirect duoshuo 使用多说评论 ➡️ https://github.com/codepiano/gitbook-plugin-duoshuo jsfiddle 插入 JSFiddle 组件 ➡️ https://github.com/Mavrin/gitbook-plugin-jsfiddle jsbin 插入 JSBin 组件 ➡️ https://github.com/jcouyang/gitbook-plugin-jsbin Advanced Emoji 支持emoji表情 ➡️ https://github.com/codeclou/gitbook-plugin-advanced-emoji Puml 使用 PlantUML 展示 uml 图 ➡️ https://github.com/GitbookIO/plugin-puml Graph 使用 function-plot 绘制数学函数图 ➡️ https://github.com/cjam/gitbook-plugin-graph Todo 添加 Todo 功能 ➡️ https://github.com/ly-tools/gitbook-plugin-todo include-csv 展示 csv 文件内容 ➡️ https://github.com/TakuroFukamizu/gitbook-plugin-include-csv musicxml 支持 musicxml 格式的乐谱渲染 ➡️ https://github.com/ymcatar/gitbook-plugin-musicxml versions-select 添加版本选择的下拉菜单，针对文档有多个版本的情况 ➡️ https://github.com/prescottprue/gitbook-plugin-versions-select rss 添加 rss 订阅功能 ➡️ https://github.com/denysdovhan/gitbook-plugin-rss multipart 将书籍分成几个部分 ➡️ https://github.com/citizenmatt/gitbook-plugin-multipart url-embed 嵌入动态内容 ➡️ https://github.com/basilvetas/gitbook-plugin-url-embed © vishon all right reserved，powered by GitbookUpdated at 2021-05-23 14:26:04 "},"linux/shell脚本模板.html":{"url":"linux/shell脚本模板.html","title":"shell脚本模板","keywords":"","body":"作为一名运维，我们经常会需要编写脚本来完成一些自动化工作，这里提供一个shell脚本的模板 #!/bin/sh ################ Version Info ################## # Create Date: 2021-05-26 # Author: vishon # Mail: nwx_qdlg@163.com # Version: 1.0 # Attention: shell脚本模板 ################################################ # 加载环境变量 # 如果脚本放到crontab中执行，会缺少环境变量，所以需要添加以下3行 . /etc/profile . ~/.bash_profile . /etc/bashrc # 脚本所在目录即脚本名称 script_dir=$( cd \"$( dirname \"$0\" )\" && pwd ) script_name=$(basename ${0}) # 日志目录 log_dir=\"${script_dir}/log\" [ ! -d ${log_dir} ] && { mkdir -p ${log_dir} } errorMsg(){ echo \"USAGE:$0 arg1 arg2 arg3\" exit 2 } doCode() { echo $1 echo $2 echo $3 } main() { if [ $# -ne 3 ];then errorMsg fi doCode \"$1\" \"$2\" \"$3\" } # 需要把隐号加上，不然传入的参数就不能有空格 main \"$@\" © vishon all right reserved，powered by GitbookUpdated at 2021-05-26 12:51:13 "},"linux/腾讯云cvm上搭建openvpn.html":{"url":"linux/腾讯云cvm上搭建openvpn.html","title":"腾讯云cvm上搭建openvpn","keywords":"","body":"我们在使用共有云的时候，有时候会需要本地电脑访问到云上的vpc机器，但是云上vpc是网络隔离的，如果不加公网ip是无法直接本地访问vpc的，其实这里我们只需要在vpc内有一台机器可以访问公网，然后再这台集群上搭建openvpn，这样本地就可以通过openvpn去直接连接vpc内其他内网机器，不用每台机器都配置公网ip了，下面我们来说下如何在腾讯云的cvm上搭建openvpn。 网络规划 vpc网段：10.0.0.0/16 openvpn分配给客户端的网段：192.168.1.0/24 openvpn服务端ip：10.0.0.13(内网)，106.53.146.250(公网) 安装openvpn # yum install openvpn # wget https://github.com/OpenVPN/easy-rsa/archive/master.zip # unzip master.zip # mv easy-rsa-master/ easy-rsa # mkdir -p /etc/openvpn/ # cp -R easy-rsa/ /etc/openvpn/ # cd /etc/openvpn/ # mkdir client server # ls client easy-rsa server 配置vars文件 # cd /etc/openvpn/easy-rsa/easyrsa3 # cp vars.example vars # vim vars 根据实际修改对应的配置 ....... set_var EASYRSA_REQ_COUNTRY \"CN\" set_var EASYRSA_REQ_PROVINCE \"SZ\" set_var EASYRSA_REQ_CITY \"GD\" set_var EASYRSA_REQ_ORG \"test\" set_var EASYRSA_REQ_EMAIL \"nwx_qdlg@163.com\" set_var EASYRSA_REQ_OU \"test\" ....... 创建server端证书 初始化目录 [root@VM-0-13-centos easyrsa3]# ls easyrsa openssl-easyrsa.cnf vars vars.example x509-types [root@VM-0-13-centos easyrsa3]# ./easyrsa init-pki Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa/easyrsa3/vars init-pki complete; you may now create a CA or requests. Your newly created PKI dir is: /etc/openvpn/easy-rsa/easyrsa3/pki [root@VM-0-13-centos easyrsa3]# ls easyrsa openssl-easyrsa.cnf pki vars vars.example x509-types 创建CA证书 [root@VM-0-13-centos easyrsa3]# ./easyrsa build-ca Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa/easyrsa3/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Enter New CA Key Passphrase: #输入CA密码，记录下 Re-Enter New CA Key Passphrase: #确认密码 Generating RSA private key, 2048 bit long modulus ..................+++ ............................................+++ e is 65537 (0x10001) You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Common Name (eg: your user, host, or server name) [Easy-RSA CA]:server # ca证书名称 CA creation complete and you may now import and sign cert requests. Your new CA certificate file for publishing is at: /etc/openvpn/easy-rsa/easyrsa3/pki/ca.crt 创建服务端证书 [root@VM-0-13-centos easyrsa3]# ./easyrsa gen-req server nopass Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa/easyrsa3/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Generating a 2048 bit RSA private key ....................+++ ........................+++ writing new private key to '/etc/openvpn/easy-rsa/easyrsa3/pki/easy-rsa-32328.KOVmFR/tmp.kdL0Yx' ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Common Name (eg: your user, host, or server name) [server]:vpc-server #输入服务端名称 Keypair and certificate request completed. Your files are: req: /etc/openvpn/easy-rsa/easyrsa3/pki/reqs/server.req key: /etc/openvpn/easy-rsa/easyrsa3/pki/private/server.key 签约服务端证书 [root@VM-0-13-centos easyrsa3]# ./easyrsa sign server server Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa/easyrsa3/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 You are about to sign the following certificate. Please check over the details shown below for accuracy. Note that this request has not been cryptographically verified. Please be sure it came from a trusted source or that you have verified the request checksum with the sender. Request subject, to be signed as a server certificate for 825 days: subject= commonName = vpc-server Type the word 'yes' to continue, or any other input to abort. Confirm request details: yes #输入yes Using configuration from /etc/openvpn/easy-rsa/easyrsa3/pki/easy-rsa-345.HZwt53/tmp.7IIgHU Enter pass phrase for /etc/openvpn/easy-rsa/easyrsa3/pki/private/ca.key: #输入之前配置的CA密码 Check that the request matches the signature Signature ok The Subject's Distinguished Name is as follows commonName :ASN.1 12:'vpc-server' Certificate is to be certified until Jun 29 09:02:24 2023 GMT (825 days) Write out database with 1 new entries Data Base Updated Certificate created at: /etc/openvpn/easy-rsa/easyrsa3/pki/issued/server.crt 创建数据穿越密钥 [root@VM-0-13-centos easyrsa3]# ./easyrsa gen-dh Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa/easyrsa3/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Generating DH parameters, 2048 bit long safe prime, generator 2 This is going to take a long time ....................+..............................................................................................................................................................................................+..........................................................................................................................+..........................................+...................+............................... DH parameters of size 2048 created at /etc/openvpn/easy-rsa/easyrsa3/pki/dh.pem 创建client证书 初始化目录 [root@VM-0-13-centos easyrsa3]# cd /etc/openvpn/client/ [root@VM-0-13-centos client]# cp -R /root/easy-rsa/easyrsa3/ . [root@VM-0-13-centos client]# ll drwxr-xr-x 3 root root 4096 Mar 26 17:07 easyrsa3 [root@VM-0-13-centos client]# cd easyrsa3/ [root@VM-0-13-centos easyrsa3]# ./easyrsa init-pki init-pki complete; you may now create a CA or requests. Your newly created PKI dir is: /etc/openvpn/client/easyrsa3/pki [root@VM-0-13-centos easyrsa3]# ls easyrsa openssl-easyrsa.cnf pki vars.example x509-types 创建客户端CA证书 [root@VM-0-13-centos easyrsa3]# ./easyrsa build-ca Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Enter New CA Key Passphrase: #输入ca密码 Re-Enter New CA Key Passphrase: #确认CA密码 Generating RSA private key, 2048 bit long modulus .....................................+++ ...........................................+++ e is 65537 (0x10001) You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Common Name (eg: your user, host, or server name) [Easy-RSA CA]:client-ca #输入ca证书名称 CA creation complete and you may now import and sign cert requests. Your new CA certificate file for publishing is at: /etc/openvpn/client/easyrsa3/pki/ca.crt 创建客户端证书 [root@VM-0-13-centos easyrsa3]# ./easyrsa gen-req client Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Generating a 2048 bit RSA private key ........................................................+++ .............................................+++ writing new private key to '/etc/openvpn/client/easyrsa3/pki/easy-rsa-1789.jZxBCq/tmp.1l4buX' Enter PEM pass phrase: #输入客户端CA密码，也是将来登录VPN客户密码！ Verifying - Enter PEM pass phrase: ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Common Name (eg: your user, host, or server name) [client]:niewx #起名字 Keypair and certificate request completed. Your files are: req: /etc/openvpn/client/easyrsa3/pki/reqs/client.req key: /etc/openvpn/client/easyrsa3/pki/private/client.key 导入客户端证书 [root@VM-0-13-centos easyrsa3]# cd /etc/openvpn/easy-rsa/easyrsa3 [root@VM-0-13-centos easyrsa3]# ./easyrsa import-req /etc/openvpn/client/easyrsa3/pki/reqs/client.req client Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa/easyrsa3/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 The request has been successfully imported with a short name of: client You may now use this name to perform signing operations on this request. 签约客户端证书 [root@VM-0-13-centos easyrsa3]# cd /etc/openvpn/easy-rsa/easyrsa3 [root@VM-0-13-centos easyrsa3]# ./easyrsa sign client client Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 You are about to sign the following certificate. Please check over the details shown below for accuracy. Note that this request has not been cryptographically verified. Please be sure it came from a trusted source or that you have verified the request checksum with the sender. Request subject, to be signed as a client certificate for 825 days: subject= commonName = niewx Type the word 'yes' to continue, or any other input to abort. Confirm request details: yes # 输入yes Using configuration from /etc/openvpn/client/easyrsa3/pki/easy-rsa-2777.2aZHdK/tmp.9RSG1Q Enter pass phrase for /etc/openvpn/client/easyrsa3/pki/private/ca.key: #客户端ca密码 Check that the request matches the signature Signature ok The Subject's Distinguished Name is as follows commonName :ASN.1 12:'niewx' Certificate is to be certified until Jun 29 09:16:55 2023 GMT (825 days) Write out database with 1 new entries Data Base Updated Certificate created at: /etc/openvpn/easy-rsa/easyrsa3/pki/issued/client.crt openvpn服务端配置 拷贝服务端证书文件 [root@VM-0-13-centos pki]# cd /etc/openvpn/easy-rsa/easyrsa3/pki [root@VM-0-13-centos pki]# cp ca.crt /etc/openvpn/server/ [root@VM-0-13-centos pki]# cp private/server.key /etc/openvpn/server/ [root@VM-0-13-centos pki]# cp issued/server.crt /etc/openvpn/server/ [root@VM-0-13-centos pki]# cp dh.pem /etc/openvpn/server/ 拷贝客户端证书 [root@VM-0-13-centos pki]# cd /etc/openvpn/client/easyrsa3 [root@VM-0-13-centos pki]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/ca.crt /etc/openvpn/client [root@VM-0-13-centos private]# cp /etc/openvpn/client/easyrsa3/pki/private/client.key /etc/openvpn/client [root@VM-0-13-centos issued]# cp /etc/openvpn/easy-rsa/easyrsa3/pki/issued/client.crt /etc/openvpn/client [root@VM-0-13-centos issued]# cd /etc/openvpn/client/ [root@VM-0-13-centos client]# ls ca.crt client.crt client.key easyrsa3 [root@VM-0-13-centos client]# cd /etc/openvpn/server/ [root@VM-0-13-centos server]# ls ca.crt dh.pem server.crt server.key 配置server.conf [root@VM-0-13-centos openvpn]# cd /etc/openvpn [root@VM-0-13-centos openvpn]# vim server.conf local 0.0.0.0 port 55555 proto tcp dev tun ca /etc/openvpn/server/ca.crt cert /etc/openvpn/server/server.crt key /etc/openvpn/server/server.key # This file should be kept secret dh /etc/openvpn/server/dh.pem server 192.168.1.0 255.255.255.0 ifconfig-pool-persist ipp.txt keepalive 10 120 persist-key persist-tun status openvpn-status.log verb 3 comp-lzo push \"route 10.0.0.0 255.0.0.0\" client-to-client log /var/log/openvpn.log 配置转发参数和iptables规则 [root@VM-0-13-centos openvpn]# sed -i '/net.ipv4.ip_forward/ s/\\(.*= \\).*/\\11/' /etc/sysctl.conf [root@VM-0-13-centos client]# iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE [root@VM-0-13-centos client]# iptables -nL -t nat Chain PREROUTING (policy ACCEPT) target prot opt source destination Chain INPUT (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination Chain POSTROUTING (policy ACCEPT) target prot opt source destination MASQUERADE all -- 192.168.1.0/24 0.0.0.0/0 启动oepnven服务端 [root@VM-0-13-centos client]# openvpn /etc/openvpn/server.conf & [1] 5785 [root@VM-0-13-centos client]# ps -ef | grep openvpn root 5785 26254 0 17:37 pts/0 00:00:00 openvpn /etc/openvpn/server.conf 本地机器安装openvpn客户端 可以到https://openvpn.net/community-downloads/下载对应系统客户端安装包 拷贝客户端证书到本地目录 主要/etc/openvpn/client目录下拷贝ca.crt，client.crt，client.key，然后配置下文件client.ovpn，内容如下 client dev tun proto tcp remote 106.53.146.250 55555 resolv-retry infinite nobind persist-key persist-tun ca ca.crt cert client1.crt key client1.key comp-lzo verb 3 运行vpn连接服务端 连接成功后，我们直接内网访问下服务，发现可以直接内网ip访问到prometheus的UI界面，这里说明我们本地电脑成功连接了vpc 自动生成客户端的脚本 [root@VM-0-13-centos client]# cd /etc/openvpn/client [root@VM-0-13-centos client]# cat auto-generate-client.sh # ! /bin/bash set -e OVPN_USER_KEYS_DIR=/etc/openvpn/client/keys EASY_RSA_VERSION=easyrsa3 EASY_RSA_DIR=/etc/openvpn/easy-rsa PKI_DIR=$EASY_RSA_DIR/$EASY_RSA_VERSION/pki for user in \"$@\" do if [ -d \"$OVPN_USER_KEYS_DIR/$user\" ]; then rm -rf $OVPN_USER_KEYS_DIR/$user rm -rf $PKI_DIR/reqs/$user.req rm -rf $PKI_DIR/private/$user.key rm -rf $PKI_DIR/issued/$user.crt sed -i '/'\"$user\"'/d' $PKI_DIR/index.txt #通过index.txt文件查看到证书的情况，首字母为R的证书就是已经被吊销的证书。 exit 0 fi cd $EASY_RSA_DIR/$EASY_RSA_VERSION # 生成客户端 ssl 证书文件 ./easyrsa build-client-full $user nopass # 整理下生成的文件 mkdir -p $OVPN_USER_KEYS_DIR/$user cp $PKI_DIR/ca.crt $OVPN_USER_KEYS_DIR/$user/ # CA 根证书 cp $PKI_DIR/issued/$user.crt $OVPN_USER_KEYS_DIR/$user/ # 客户端证书 cp $PKI_DIR/private/$user.key $OVPN_USER_KEYS_DIR/$user/ # 客户端证书密钥 cp /etc/openvpn/client/sample.ovpn $OVPN_USER_KEYS_DIR/$user/$user.ovpn # 客户端配置文件 sed -i 's/admin/'\"$user\"'/g' $OVPN_USER_KEYS_DIR/$user/$user.ovpn cd $OVPN_USER_KEYS_DIR zip -r $user.zip $user done exit 0 脚本会自动生成客户端证书，执行方式如下，如果需要生成多个用户则在参数加上就行 # sh auto-generate-client.sh test1 test2 ..... 将对应的zip包拷贝给用户，然后再openvpn中指定对应的ovpn文件进行配置下连接即可 © vishon all right reserved，powered by GitbookUpdated at 2021-05-18 18:41:27 "},"linux/vmware安装centos环境设置静态的ip地址.html":{"url":"linux/vmware安装centos环境设置静态的ip地址.html","title":"vmware安装centos环境设置静态的ip地址","keywords":"","body":"vmware安装centos环境设置静态的ip地址 有的时候我们为了学习测试，会在自己的笔记本上搭建虚拟机，今天我们来讲下在windows上如何安装centos环境并且设置静态ip，如果是土豪，可以直接到云上购买机器，本篇文章可以忽略。 笔记本主机IP为设置自动获取，不管什么情况下，不受虚拟机影响，只要连接外网就可以正常上网； 只要笔记本主机可以正常访问外网，启动虚拟机中的CentOS 7系统就可以正常访问外网，无需再进行任何设置； 虚拟机设置为固定IP，不管主机在什么网络环境下，是断网环境，还是连接任何网段访问外网的环境下，虚拟机的IP都固定不变，而且使用终端连接，始终不变，正常连接； 虚拟机的固定IP可以按照自己想设置的IP地址网段随意设置，比如我就想设置固定IP为192.168.2.2。 以上4点，网上我没有找到一个帖子可以达到我要求的效果，经过我这段时间研究，经过各种尝试，期间出现各种问题，测试稳定后，总结如下分享给大家，希望对大家有所帮助，少走弯路。 采用方式为NAT模式+固定IP的模式。 配置环境说明：主机为Win10家庭版，虚拟机为VMware Workstation 12 Pro中文版，虚拟机中的Linux系统为CentOS 7 64位。 设置虚拟机的网络连接方式 按照如下图设置，英文版的对照设置即可 配置虚拟机的NAT模式具体地址参数 编辑--虚拟网络编辑器--更改设置 选择VMnet8--取消勾选使用本地DHCP--设置子网IP--网关IP设置（记住此处设置，后面要用到），如下图 说明：修改子网IP设置，实现自由设置固定IP，若你想设置固定IP为192.168.2.2-255，比如192.168.2.2，则子网IP为192.168.2.0；若你想设置固定IP为192.168.1.2-255，比如192.168.1.2，则子网IP为192.168.1.0； 网关IP可以参照如下格式修改：192.168.2.1 配置笔记本主机具体VMnet8本地地址参数 说明：第6步中的IP地址随意设置，但是要保证不能跟你要设置虚拟机的固定IP一样。 修改虚拟机中的CentOS 7系统为固定IP的配置文件 进入centos7命令行界面，修改如下内容 #cd /etc/sysconfig/network-scripts/ #vi ifcfg-eno16777736 说明： #将IPV6…..协议都注释； BOOTPROTO=static #开机协议，有dhcp及static； ONBOOT=yes #设置为开机启动； DNS1=114.114.114.114 #这个是国内的DNS地址，是固定的； IPADDR=192.168.2.2 #你想要设置的固定IP，理论上192.168.2.2-255之间都可以，请自行验证； NETMASK=255.255.255.0 #子网掩码，不需要修改； GATEWAY=192.168.2.1 #网关，这里是你在“2.配置虚拟机的NAT模式具体地址参数”中的（2）选择VMnet8--取消勾选使用本地DHCP--设置子网IP--网关IP设置。 重启网络服务 service network restart 检验配置是否成功 查看修改后的固定IP为192.168.2.2，配置正确 ifconfig 测试虚拟机中的CentOS 7系统是否能连外网，有数据返回，说明可以连接外网 ping www.baidu.com 测试本机是否能ping通虚拟机的固定IP 有数据返回，说明可以使用终端工具正常连接 鼠标放到开始菜单右键，选择命令提示符（管理员），打开命令操作界面： ping 192.168.2.2 远程终端连接 若连接失败是因为CentOS 7的防火墙端口没有打开，比如开启80，3306端口，最后一定要重启防火墙 #查看防火墙状态 systemctl status firewalld #开启80端口 firewall-cmd --zone=public --add-port=80/tcp --permanent #开启3306端口 firewall-cmd --zone=public --add-port=3306/tcp --permanent #重启防火墙： firewall-cmd --reload 连接成功 © vishon all right reserved，powered by GitbookUpdated at 2021-05-22 10:44:15 "},"database/mysql运维笔记.html":{"url":"database/mysql运维笔记.html","title":"mysql运维笔记","keywords":"","body":"Mysql运维知识 这里总结下mysql数据库常用的运维操作 登录MySQL 登录MySQL的命令是mysql， mysql 的使用语法如下： mysql [-u username] [-h host] [-p[password]] [dbname] username 与 password 分别是 MySQL 的用户名与密码，mysql的初始管理帐号是root，没有密码，注意：这个root用户不是Linux的系统用户。MySQL默认用户是root，由于初始没有密码，第一次进时只需键入mysql即可。 [root@test1 local]# mysql Welcome to the MySQL monitor.　Commands end with ; or \\g. Your MySQL connection id is 1 to server version: 4.0.16-standard Type 'help;' or '\\h' for help. Type '\\c' to clear the buffer. mysql> 出现了“mysql>”提示符，恭喜你，安装成功！ 增加了密码后的登录格式如下： mysql -u root -p Enter password: (输入密码) 其中-u后跟的是用户名，-p要求输入密码，回车后在输入密码处输入密码。 注意：这个mysql文件在/usr/bin目录下，与后面讲的启动文件/etc/init.d/mysql不是一个文件。 MySQL的几个重要目录 MySQL安装完成后不象SQL Server默认安装在一个目录，它的数据库文件、配置文件和命令文件分别在不同的目录，了解这些目录非常重要，尤其对于Linux的初学者，因为Linux本身的目录结构就比较复杂，如果搞不清楚MySQL的安装目录那就无从谈起深入学习。 下面就介绍一下这几个目录。 数据库目录 /var/lib/mysql/ 配置文件 /usr/share/mysql（mysql.server命令及配置文件） 相关命令 /usr/bin(mysqladmin mysqldump等命令) 启动脚本 /etc/rc.d/init.d/（启动脚本文件mysql的目录） 修改登录密码 MySQL默认没有密码，安装完毕增加密码的重要性是不言而喻的。 命令 usr/bin/mysqladmin -u root password ‘new-password’ 格式：mysqladmin -u用户名 -p旧密码 password 新密码 例子 例1：给root加个密码123456。 键入以下命令 ： [root@test1 local]# /usr/bin/mysqladmin -u root password 123456 注：因为开始时root没有密码，所以-p旧密码一项就可以省略了。 测试是否修改成功 不用密码登录 [root@test1 local]# mysql ERROR 1045: Access denied for user: ‘root@localhost’ (Using password: NO) 显示错误，说明密码已经修改。 用修改后的密码登录 [root@test1 local]# mysql -u root -p Enter password: (输入修改后的密码123456) Welcome to the MySQL monitor.　Commands end with ; or \\g. Your MySQL connection id is 4 to server version: 4.0.16-standard Type 'help;' or '\\h' for help. Type '\\c' to clear the buffer. mysql> 成功！ 这是通过mysqladmin命令修改口令，也可通过修改库来更改口令。 启动与停止 启动 MySQL安装完成后启动文件mysql在/etc/init.d目录下，在需要启动时运行下面命令即可。 [root@test1 init.d]# /etc/init.d/mysql start 停止 /usr/bin/mysqladmin -u root -p shutdown 自动启动 1）察看mysql是否在自动启动列表中 [root@test1 local]#　/sbin/chkconfig –list 2）把MySQL添加到你系统的启动服务组里面去 [root@test1 local]#　/sbin/chkconfig　– add　mysql 3）把MySQL从启动服务组里面删除。 [root@test1 local]#　/sbin/chkconfig　– del　mysql 更改MySQL目录 MySQL默认的数据文件存储目录为/var/lib/mysql。假如要把目录移到/home/data下需要进行下面几步 1.home目录下建立data目录 cd /home mkdir data 2.把MySQL服务进程停掉 mysqladmin -u root -p shutdown 3.把/var/lib/mysql整个目录移到/home/data mv /var/lib/mysql　/home/data/ 这样就把MySQL的数据文件移动到了/home/data/mysql下 4.找到my.cnf配置文件 如果/etc/目录下没有my.cnf配置文件，请到/usr/share/mysql/下找到*.cnf文件，拷贝其中一个到/etc/并改名为my.cnf)中。命令如下： [root@test1 mysql]# cp /usr/share/mysql/my-medium.cnf　/etc/my.cnf 5.编辑MySQL的配置文件/etc/my.cnf 为保证MySQL能够正常工作，需要指明mysql.sock文件的产生位置。 修改socket=/var/lib/mysql/mysql.sock一行中等号右边的值为：/home/mysql/mysql.sock 。操作如下： vi　 my.cnf　　　 (用vi工具编辑my.cnf文件，找到下列数据修改之) # The MySQL server [mysqld] port　　　= 3306 #socket　 = /var/lib/mysql/mysql.sock（原内容，为了更稳妥用“#”注释此行） socket　 = /home/data/mysql/mysql.sock　　　（加上此行） 6.修改MySQL启动脚本/etc/rc.d/init.d/mysql 最后，需要修改MySQL启动脚本/etc/rc.d/init.d/mysql，把其中datadir=/var/lib/mysql一行中，等号右边的路径改成你现在的实际存放路径：home/data/mysql。 [root@test1 etc]# vi　/etc/rc.d/init.d/mysql #datadir=/var/lib/mysql　　　　（注释此行） datadir=/home/data/mysql　　 （加上此行） 7.重新启动MySQL服务 /etc/rc.d/init.d/mysql　start 或用reboot命令重启Linux，如果工作正常移动就成功了，否则对照前面的7步再检查一下。 MySQL的常用操作 注意：MySQL中每个命令后都要以分号；结尾。 显示数据库 mysql> show databases; +----------+ | Database | +----------+ | mysql　　| | test　　 | +----------+ rows in set (0.04 sec) Mysql刚安装完有两个数据库：mysql和test。mysql库非常重要，它里面有MySQL的系统信息，我们改密码和新增用户，实际上就是用这个库中的相关表进行操作。 显示数据库中的表 mysql> use mysql; （打开库，对每个库进行操作就要打开此库，类似于foxpro ） Database changed mysql> show tables; +-----------------+ | Tables_in_mysql | +-----------------+ | columns_priv　　| | db　　　　　　　| | func　　　　　　| | host　　　　　　| | tables_priv　　 | | user　　　　　　| +-----------------+ 6 rows in set (0.01 sec) 显示数据表的结构 describe 表名; 显示表中的记录 select * from 表名; 例如：显示mysql库中user表中的纪录。所有能对MySQL用户操作的用户都在此表中。 Select * from user; 建库 create database 库名; 例如：创建一个名字位aaa的库 mysql> create databases aaa; 建表 use 库名； create table 表名 (字段设定列表)； 例如：在刚创建的aaa库中建立表name,表中有id(序号，自动增长)，xm（姓名）,xb（性别）,csny（出身年月）四个字段 use aaa; mysql> create table name (id int(3) auto_increment not null primary key, xm char(8),xb char(2),csny date); 可以用describe命令察看刚建立的表结构。 mysql> describe name; +-------+---------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra　　　　　| +-------+---------+------+-----+---------+----------------+ | id　　| int(3)　|　　　| PRI | NULL　　| auto_increment | | xm　　| char(8) | YES　|　　 | NULL　　|　　　　　　　　| | xb　　| char(2) | YES　|　　 | NULL　　|　　　　　　　　| | csny　| date　　| YES　|　　 | NULL　　|　　　　　　　　| +-------+---------+------+-----+---------+----------------+ 增加记录 例如：增加几条相关纪录。 mysql> insert into name values(”,’张三’,’男’,’1971-10-01′); mysql> insert into name values(”,’白云’,’女’,’1972-05-20′); 可用select命令来验证结果。 mysql> select * from name; +—-+——+——+————+ | id | xm　 | xb　 | csny　　　 | +—-+——+——+————+ |　1 | 张三 | 男　 | 1971-10-01 | |　2 | 白云 | 女　 | 1972-05-20 | +—-+——+——+————+ 修改纪录 例如：将张三的出生年月改为1971-01-10 mysql> update name set csny=’1971-01-10′ where xm=’张三’; 删除纪录 例如：删除张三的纪录。 mysql> delete from name where xm=’张三’; 删库和删表 drop database 库名; drop table 表名； 增加MySQL用户 格式：grant select on 数据库.* to 用户名@登录主机 identified by “密码” 1、增加一个用户user_1密码为123，让他可以在任何主机上登录，并对所有数据库有查询、插入、修改、删除的权限。首先用以root用户连入MySQL，然后键入以下命令： mysql> grant select,insert,update,delete on *.* to user_1@”%” Identified by “123″; 例1增加的用户是十分危险的，如果知道了user_1的密码，那么他就可以在网上的任何一台电脑上登录你的MySQL数据库并对你的数据为所欲为了，解决办法见例2。 2、增加一个用户user_2密码为123,让此用户只可以在localhost上登录，并可以对数据库aaa进行查询、插入、修改、删除的操作（localhost指本地主机，即MySQL数据库所在的那台主机），这样用户即使用知道user_2的密码，他也无法从网上直接访问数据库，只能通过MYSQL主机来操作aaa库。 mysql>grant select,insert,update,delete on aaa.* to user_2@localhost identified by “123″; 用新增的用户如果登录不了MySQL，在登录时用如下命令： mysql -u user_1 -p　-h 192.168.113.50　（-h后跟的是要登录主机的ip地址） mysql的数据导入导出 mysql数据库执行导入导出命令在可执行的mysql目录下执行 从数据库导出数据库或表文件： mysqldump -u用戶名 -p密码 -d 数据库名 表名 > 脚本名; 导出整个数据库结构和数据 mysqldump -h localhost -uroot -p123456 database > e:\\dump.sql 导出单个数据表结构和数据 mysqldump -h localhost -uroot -p123456 database table > e:\\dump.sql 导出整个数据库结构（不包含数据） mysqldump -h localhost -uroot -p123456 -d database > e:\\dump.sql 导出单个数据表结构（不包含数据） mysqldump -h localhost -uroot -p123456 -d database table > e:\\dump.sql 导入数据库或表到数据库（数据库要先建好） 方法1：mysql -h localhost -uroot -p123456 -d database table mysql中用户的权限分配 用户管理 mysql>use mysql; 查看 mysql> select host,user,password from user ; 创建 mysql> create user zx_root IDENTIFIED by 'xxxxx'; //identified by 会将纯文本密码加密作为散列值存储 修改 mysql>rename user feng to newuser；//mysql 5之后可以使用，之前需要使用update 更新user表 删除 mysql>drop user newuser; //mysql5之前删除用户时必须先使用revoke 删除用户权限，然后删除用户，mysql5之后drop 命令可以删除用户的同时删除用户的相关权限 更改密码 mysql> set password for zx_root =password('xxxxxx'); mysql> update mysql.user set password=password('xxxx') where user='otheruser' 查看用户权限 mysql> show grants for zx_root; 赋予权限 mysql> grant select on dmc_db.* to zx_root; 回收权限 mysql> revoke select on dmc_db.* from zx_root; //如果权限不存在会报错 上面的命令也可使用多个权限同时赋予和回收，权限之间使用逗号分隔 mysql> grant select，update，delete ，insert on dmc_db.* to zx_root; 如果想立即看到结果使用 flush privileges ; 命令更新 设置权限时必须给出一下信息 要授予的权限 被授予访问权限的数据库或表 用户名 grant和revoke可以在几个层次上控制访问权限 整个服务器，使用 grant ALL 和revoke ALL 整个数据库，使用on database.* 特点表，使用on database.table 特定的列 特定的存储过程 user表中host列的值的意义 % 匹配所有主机 localhost localhost不会被解析成IP地址，直接通过UNIXsocket连接 127.0.0.1 会通过TCP/IP协议连接，并且只能在本机访问； ::1 ::1就是兼容支持ipv6的，表示同ipv4的127.0.0.1 grant 普通数据用户，查询、插入、更新、删除 数据库中所有表数据的权利。 grant select on testdb.* to common_user@’%’ grant insert on testdb.* to common_user@’%’ grant update on testdb.* to common_user@’%’ grant delete on testdb.* to common_user@’%’ 或者，用一条 MySQL 命令来替代： grant select, insert, update, delete on testdb.* to common_user@’%’ 9>.grant 数据库开发人员，创建表、索引、视图、存储过程、函数。。。等权限。 grant 创建、修改、删除 MySQL 数据表结构权限。 grant create on testdb.* to developer@’192.168.0.%’; grant alter on testdb.* to developer@’192.168.0.%’; grant drop on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 外键权限。 grant references on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 临时表权限。 grant create temporary tables on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 索引权限。 grant index on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 视图、查看视图源代码 权限。 grant create view on testdb.* to developer@’192.168.0.%’; grant show view on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 存储过程、函数 权限。 grant create routine on testdb.* to developer@’192.168.0.%’; -- now, can show procedure status grant alter routine on testdb.* to developer@’192.168.0.%’; -- now, you can drop a procedure grant execute on testdb.* to developer@’192.168.0.%’; 10>.grant 普通 DBA 管理某个 MySQL 数据库的权限。 grant all privileges on testdb to dba@’localhost’ 其中，关键字 “privileges” 可以省略。 11>.grant 高级 DBA 管理 MySQL 中所有数据库的权限。 grant all on *.* to dba@’localhost’ 12>.MySQL grant 权限，分别可以作用在多个层次上。 1. grant 作用在整个 MySQL 服务器上： grant select on *.* to dba@localhost; -- dba 可以查询 MySQL 中所有数据库中的表。 grant all on *.* to dba@localhost; -- dba 可以管理 MySQL 中的所有数据库 2. grant 作用在单个数据库上： grant select on testdb.* to dba@localhost; -- dba 可以查询 testdb 中的表。 3. grant 作用在单个数据表上： grant select, insert, update, delete on testdb.orders to dba@localhost; 4. grant 作用在表中的列上： grant select(id, se, rank) on testdb.apache_log to dba@localhost; 5. grant 作用在存储过程、函数上： grant execute on procedure testdb.pr_add to ’dba’@’localhost’ grant execute on function testdb.fn_add to ’dba’@’localhost’ 注意：修改完权限以后 一定要刷新服务，或者重启服务，刷新服务用：FLUSH PRIVILEGES。 mysql主从复制和读写分离的搭建 Mysql的主从复制的搭建，大家可以采用在linux，windows，docker，dockr-compose来搭建mysql 本次采用方式为docker-composer来搭建多个mysql服务端 目录结构如下 docker-compose.yml文件内容 version: '2' services: mysql-master: build: context: ./ dockerfile: master/Dockerfile environment: - \"MYSQL_ROOT_PASSWORD=root\" - \"MYSQL_DATABASE=replicas_db\" links: - mysql-slave ports: - \"33065:3306\" restart: always hostname: mysql-master mysql-slave: build: context: ./ dockerfile: slave/Dockerfile environment: - \"MYSQL_ROOT_PASSWORD=root\" - \"MYSQL_DATABASE=replicas_db\" ports: - \"33066:3306\" restart: always hostname: mysql-slave Master的dockerfile和my.cnf Dockerfile内容 FROM mysql:5.7 MAINTAINER harrison ADD ./master/my.cnf /etc/mysql/my.cnf my.cnf内容 [mysqld] ## 设置server_id，一般设置为IP，注意要唯一 server_id=100 ## 复制过滤：也就是指定哪个数据库不用同步（mysql库一般不同步） binlog-ignore-db=mysql ## 开启二进制日志功能，可以随便取，最好有含义（关键就是这里了） log-bin=replicas-mysql-bin ## 为每个session分配的内存，在事务过程中用来存储二进制日志的缓存 binlog_cache_size=1M ## 主从复制的格式（mixed,statement,row，默认格式是statement） binlog_format=mixed ## 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。 expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 ## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 slave_skip_errors=1062 Slave的dockerfile和my.cnf Dockerfile内容 FROM mysql:5.7 MAINTAINER harrison ADD ./slave/my.cnf /etc/mysql/my.cnf my.cnf内容 [mysqld] ## 设置server_id，一般设置为IP，注意要唯一 server_id=101 ## 复制过滤：也就是指定哪个数据库不用同步（mysql库一般不同步） binlog-ignore-db=mysql ## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用 log-bin=replicas-mysql-slave1-bin ## 为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存 binlog_cache_size=1M ## 主从复制的格式（mixed,statement,row，默认格式是statement） binlog_format=mixed ## 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。 expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 ## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 slave_skip_errors=1062 ## relay_log配置中继日志 relay_log=replicas-mysql-relay-bin ## log_slave_updates表示slave将复制事件写进自己的二进制日志 log_slave_updates=1 ## 防止改变数据(除了特殊的线程) read_only=1 进入 docker 目录，运行 docker-compose 启动命令。 $ docker-compose up -d 检查从库的起始状态 $ show master status; 从数据库处于 未同步复制状态。 检查主库的状态 $ show master status; 记录 主数据库 binary-log的文件名称和数据同步起始位置。 File: replicas-mysql-bin.000003 Position: 154 从库配置主库信息 在 从数据库上运行主数据库的相关配置sql进行主从关联 CHANGE MASTER TO MASTER_HOST='mysql-master', MASTER_USER='root', MASTER_PASSWORD='root', MASTER_LOG_FILE='replicas-mysql-bin.000003', MASTER_LOG_POS=154; 重新启动 slave 服务 $ stop slave $ start slave 进一步检查从数据库的状态信息，两者已经进行数据同步关联。 master修改密码如何同步slave 所以，更新密码后，只需要： change master to master_user='replication user', master_password='new passwd'; mysql慢查询的原因 没有索引或者没有用到索引(这是查询慢最常见问题，是程序设计的缺陷) I/O吞吐量小，形成了瓶颈效应。 没有创建计算列导致查询不优化。 内存不足 网络速度慢 查询出的数据量过大(可以采用多次查询，其他的方法降低数据量) 锁或者死锁(这也是查询慢最常见的问题，是程序设计的缺陷) sp_lock,sp_who,活动的用户查看,原因是读写竞争资源。 返回了不必要的行和列 查询语句不好，没有优化 © vishon all right reserved，powered by GitbookUpdated at 2021-05-22 16:47:07 "},"database/mongodb运维笔记.html":{"url":"database/mongodb运维笔记.html","title":"mongodb运维笔记","keywords":"","body":"Mongdb运维知识 mongodb集群的搭建 系统环境 Centos7.5、MongoDB4.0.2、关闭防火墙。 Ip 路由服务端口 配置服务端口 分片1端口 分片2端口 分片3端口 192.168.30.30 27017 27018 27001 27002 27003 192.168.30.31 27017 27018 27001 27002 27003 192.168.30.32 27017 27018 27001 27002 27003 三台机器的配置服务(27018)形成复制集，分片1、2、3也在各机器都部署一个实例，它们之间形成复制集，客户端直接连接3个路由服务与之交互，配置服务和分片服务对客户端是透明的。 服务器的安装及配置(3台服务器执行相同操作) 下载解压MongoDB 到MongoDB官网下载：https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.6.tgz 解压到/home/mongodb，设置环境变量: echo 'export PATH=$PATH:/home/mongodb/bin' >> /etc/profile 保存后执行： source /etc/profile 创建路由、配置、分片等的相关目录与文件 启动配置文件存放的文件夹：mkdir -p /home/mongodb/conf 配置服务数据存放目录：mkdir -p /home/mongodb/data/config 分片1服务数据存放目录：mkdir -p /home/mongodb/data/shard1 分片2服务数据存放目录：mkdir -p /home/mongodb/data/shard2 分片3服务数据存放目录：mkdir -p /home/mongodb/data/shard3 配置服务日志存放文件：touch /home/mongodb/log/config.log 路由服务日志存放文件：touch /home/mongodb/log/mongos.log 分片1服务日志存放文件：touch /home/mongodb/log/shard1.log 分片2服务日志存放文件：touch /home/mongodb/log/shard2.log 分片3服务日志存放文件：touch /home/mongodb/log/shard3.log mkdir -p /home/mongodb/conf mkdir -p /home/mongodb/data/config mkdir -p /home/mongodb/data/shard1 mkdir -p /home/mongodb/data/shard2 mkdir -p /home/mongodb/data/shard3 mkdir -p /home/mongodb/log touch /home/mongodb/log/config.log touch /home/mongodb/log/mongos.log touch /home/mongodb/log/shard1.log touch /home/mongodb/log/shard2.log touch /home/mongodb/log/shard3.log 配置服务器部署(3台服务器执行相同操作) 在/home/mongodb/conf目录创建config.conf [root@master conf]# cat config.conf dbpath=/home/mongodb/data/config logpath=/home/mongodb/log/config.log port=27018 logappend=true fork=true maxConns=5000 #复制集名称 replSet=configs #置参数为true configsvr=true #允许任意机器连接 bind_ip=0.0.0.0 配置复制集 scp config.conf root@192.168.30.31:/home/mongodb/conf scp config.conf root@192.168.30.32:/home/mongodb/conf 分别启动三台服务器的配置服务： mongod -f /home/mongodb/conf/config.conf 连接mongo,只需在任意一台机器执行即可： mongo --host 10.211.55.3 --port 27018 切换数据库： use admin 初始化复制集： rs.initiate({_id:\"configs\",members:[{_id:0,host:\"192.168.30.30:27018\"},{_id:1,host:\"192.168.30.31:27018\"}, {_id:2,host:\"192.168.30.32:27018\"}]}) 其中_id:\"configs\"的configs是上面config.conf配置文件里的复制集名称，把三台服务器的配置服务组成复制集。 查看状态： rs.status() 等几十秒左右，执行上面的命令查看状态，三台机器的配置服务就已形成复制集，其中1台为PRIMARY，其他2台为SECONDARY。 分片服务部署(3台服务器执行相同操作) 在/home/mongodb/conf目录创建shard1.conf、shard2.conf、shard3.conf，内容如下： [root@master conf]# cat shard1.conf dbpath=/home/mongodb/data/shard1 #其他2个分片对应修改为shard2、shard3文件夹 logpath=/home/mongodb/log/shard1.log #其他2个分片对应修改为shard2.log、shard3.log port=27001 #其他2个分片对应修改为27002、27003 logappend=true fork=true maxConns=5000 storageEngine=mmapv1 shardsvr=true replSet=shard1 #其他2个分片对应修改为shard2、shard3 bind_ip=0.0.0.0 端口分别是27001、27002、27003，分别对应shard1.conf、shard2.conf、shard3.conf。 还有数据存放目录、日志文件这几个地方都需要对应修改。 在3台机器的相同端口形成一个分片的复制集，由于3台机器都需要这3个文件，所以根据这9个配置文件分别启动分片服务： scp shard* root@192.168.30.30:/home/mongodb/conf scp shard* root@192.168.30.31:/home/mongodb/conf scp shard* root@192.168.30.32:/home/mongodb/conf mongod --smallfiles -f /home/mongodb/conf/shard1.conf mongod --smallfiles -f /home/mongodb/conf/shard2.conf mongod --smallfiles -f /home/mongodb/conf/shard3.conf2 将分片配置为复制集连接mongo，只需在任意一台机器执行即可： mongo --host 192.168.30.30 --port 27001 //这里以shard1为例，其他两个分片则再需对应连接到27002、27003的端口进行操作即可 切换数据库： use admin 初始化复制集： rs.initiate({_id:\"shard1\",members:[{_id:0,host:\"192.168.30.30:27001\"},{_id:1,host:\"192.168.30.31:27001\"},{_id:2,host:\"192.168.30.32:27001\"}]}) 以上是基于分片1来操作，同理，其他2个分片也要连到各自的端口来执行一遍上述的操作，让3个分片各自形成1主2从的复制集，注意端口及仲裁节点的问题即可，操作完成后3个分片都启动完成，并完成复制集模式。 mongo --host 192.168.30.30 --port 27002 use admin rs.initiate({_id:\"shard2\",members:[{_id:0,host:\"192.168.30.30:27002\"},{_id:1,host:\"192.168.30.31:27002\"},{_id:2,host:\"192.168.30.32:27002\"}]}) mongo --host 192.168.30.30 --port 27003 use admin rs.initiate({_id:\"shard3\",members:[{_id:0,host:\"192.168.30.30:27003\"},{_id:1,host:\"192.168.30.31:27003\"},{_id:2,host:\"192.168.30.32:27003\"}]}) 路由服务部署(3台服务器执行相同操作) 创建mongos.conf 在/home/mongodb/conf目录创建mongos.conf，内容如下： [root@master conf]# cat mongos.conf logpath=/home/mongodb/log/mongos.log logappend = true port = 27017 fork = true configdb = configs/192.168.30.30:27018,192.168.30.31:27018,192.168.30.32:27018 maxConns=20000 bind_ip=0.0.0.0 scp mongos.conf root@192.168.30.31:/home/mongodb/conf scp mongos.conf root@192.168.30.32:/home/mongodb/conf 启动mongos 分别在三台服务器启动： mongos -f /home/mongodb/conf/mongos.conf 启动分片功能 连接mongo： mongo --host 10.211.55.3 --port 27017 切换数据库： use admin 添加分片，只需在一台机器执行即可： sh.addShard(\"shard1/192.168.30:27001,192.168.30.31:27001,192.168.30.32:27001\") sh.addShard(\"shard2/192.168.30:27001,192.168.30.31:27001,192.168.30.32:27001\") sh.addShard(\"shard3/192.168.30:27001,192.168.30.31:27001,192.168.30.32:27001\") 查看集群状态： sh.status() 实现分片功能 设置分片chunk大小 use config db.setting.save({\"_id\":\"chunksize\",\"value\":1}) # 设置块大小为1M是方便实验，不然需要插入海量数据 模拟写入数据 use calon for(i=1;i创建索引对表进行分片 db.user.createIndex({\"id\":1}) # 以\"id\"作为索引 sh.shardCollection(calon.user\",{\"id\":1}) # 根据\"id\"对user表进行分片 sh.status() # 查看分片情况 到此，MongoDB分布式集群就搭建完毕。 docker中运行mongodb 镜像下载 执行 docker search mongo 命令和docker pull mongo 运行mongo镜像 docker run \\ --name mongodb_server \\ -p 27017:27017 \\ -v /mysoft/mongodb/configdb:/data/configdb/ \\ -v /mysoft/mongodb/db/:/data/db/ \\ -d mongo --auth 采用admin用户进入mongodb docker exec -it a7e5d4e4ca69 mongo admin 创建admin管理员账户 db.createUser({ user: 'admin', pwd: 'admin123456', roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ] }); 以 admin 用户身份进入mongo docker exec -it a7e5d4e4ca69 mongo admin 对 admin 用户 进行身份认证 db.auth(\"admin\",\"admin123456\"); 创建 用户、密码和数据库 db.createUser({ user: 'swen', pwd: 'swen123456', roles: [ { role: \"readWrite\", db: \"app\" } ] }); 以 admin 用户身份进入mongo docker exec -it a7e5d4e4ca69 mongo admin 对 swen 进行身份认证 db.auth(\"swen\",\"swen123456\"); 切换数据库 use app 添加数据 db.test.save({name:\"zhangsan\"}); 查看数据库 show dbs 数据库集合（类似于表）操作命令 show collections db.createCollection(\"mycol\", { capped : true, autoIndexId : true, size : 6142800, max : 10000 } ) db.mycol2.insert({\"name\" : \"菜鸟教程\"}) db.mycol2.drop() 数据库文档（类似于一行一行数据）操作命令 db.col.insert({title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库', by: '菜鸟教程', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100 }) db.col.find() document=({title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库', by: '菜鸟教程', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100 }); db.col.insert(document) var document = db.collection.insertOne({\"a\": 3}) document { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"571a218011a82a1d94c02333\") } db.col.update({'title':'MongoDB 教程'},{$set:{'title':'MongoDB'}}) db.col.find().pretty() db.col.save({ \"_id\" : ObjectId(\"56064f89ade2f21f36b03136\"), \"title\" : \"MongoDB\", \"description\" : \"MongoDB 是一个 Nosql 数据库\", \"by\" : \"Runoob\", \"url\" : \"http://www.runoob.com\", \"tags\" : [ \"mongodb\", \"NoSQL\" ], \"likes\" : 110 }) -- pretty() 方法以格式化的方式来显示所有文档。 db.col.remove({'title':'MongoDB 教程'}) db.col.remove(DELETION_CRITERIA,1) db.repairDatabase() db.inventory.deleteMany({ \"likes\" : 110 }) db.col.find({\"likes\": {$gt:50}, $or: [{\"by\": \"菜鸟教程\"},{\"title\": \"MongoDB 教程\"}]}).pretty() mongodb的导入导出 导出工具mongoexport Mongodb中的mongoexport工具可以把一个collection导出成JSON格式或CSV格式的文件。可以通过参数指定导出的数据项，也可以根据指定的条件导出数据。 可通过 mongoexport --help 命令查看具体使用方法 参数说明： -h:指明数据库宿主机的IP -u:指明数据库的用户名 -p:指明数据库的密码 -d:指明数据库的名字 -c:指明collection的名字 -f:指明要导出那些列 -o:指明到要导出的文件名 -q:指明导出数据的过滤条件 示例： 导出goods数据库下students集合的数据 执行图中命令 bin目录下生成students.dat文件，内容如下(也可在命令行中执行 type students.dat 查看) 从上面的结果可以看出，我们在导出数据时没有显示指定导出样式 ，默认导出了JSON格式的数据。实际情况下常常需要导出csv格式的数据，命令如下 mongoexport -d goods -c students --csv -f classid,name,age -o students_csv.dat 参数详解： -d:指明使用的库，本例中为goods -c:指明要导出的集合，本例中为students -o:指明要导出的文件名，本例中为students_csv.dat -csv：指明要导出为csv格式 -f：指明需要导出classid、name、age这3列的数据 导入工具mongoimport Mongodb中的mongoimport工具可以把一个特定格式文件中的内容导入到指定的collection中。该工具可以导入JSON格式数据，也可以导入CSV格式数据。 可通过 mongoimport --help 命令查看具体使用方法 参数说明： -h:指明数据库宿主机的IP -u:指明数据库的用户名 -p:指明数据库的密码 -d:指明数据库的名字 -c:指明collection的名字 -f:指明要导入那些列 示例 先删除students集合数据，验证 db.students.remove({}); db.students.find(); 导入之前导出的students.dat文件 上面演示的是导入JSON格式的文件中的内容，如果要导入CSV格式文件中的内容，则需要通过--type参数指定导入格式 mongoimport -d goods -c students --type csv --headerline --file students_csv.dat 参数详解 -d:指明数据库名，本例中为goods -c:指明collection名，本例中为students -type:指明要导入的文件格式 -headerline:指明第一行是列名，不需要导入 -file：指明要导入的文件 students_csv.dat：导入的文件名 © vishon all right reserved，powered by GitbookUpdated at 2021-05-23 14:18:24 "},"database/redis运维笔记.html":{"url":"database/redis运维笔记.html","title":"redis运维笔记","keywords":"","body":"redis cluster安装 下载并解压 cd /root/software wget http://download.redis.io/releases/redis-3.2.4.tar.gz tar -zxvf redis-3.2.4.tar.gz 编译安装 cd redis-3.2.4 make && make install 将redis-trib.rb复制到/usr/local/bin目录下 cd src cp redis-trib.rb /usr/local/bin/ 创建 Redis 节点 首先在 192.168.31.245 机器上 /root/software/redis-3.2.4 目录下创建 redis_cluster 目录； mkdir redis_cluster 在 redis_cluster 目录下，创建名为7000、7001、7002的目录，并将 redis.conf 拷贝到这三个目录中 mkdir 7000 7001 7002 cp redis.conf redis_cluster/7000 cp redis.conf redis_cluster/7001 cp redis.conf redis_cluster/7002 分别修改这三个配置文件，修改如下内容 port 7000 //端口7000,7002,7003 bind 本机ip //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群 daemonize yes //redis后台运行 pidfile /var/run/redis_7000.pid //pidfile文件对应7000,7001,7002 cluster-enabled yes //开启集群 把注释#去掉 cluster-config-file nodes_7000.conf //集群的配置 配置文件首次启动自动生成 7000,7001,7002 cluster-node-timeout 15000 //请求超时 默认15秒，可自行设置 appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志　 masterauth abc //注意:如果对集群设置密码,需做以下改动,否则不能设置密码。 requirepass abc //requirepass和masterauth都需要设置，并且每个节点的密码需要一致，否则发生主从切换时，就会遇到授权问题，可以模拟并观察日志 接着在另外一台机器上（192.168.31.210），的操作重复以上三步，只是把目录改为7003、7004、7005，对应的配置文件也按照这个规则修改即可 启动各个节点 第一台机器上执行 redis-server redis_cluster/7000/redis.conf redis-server redis_cluster/7001/redis.conf redis-server redis_cluster/7002/redis.conf 另外一台机器上执行 redis-server redis_cluster/7003/redis.conf redis-server redis_cluster/7004/redis.conf redis-server redis_cluster/7005/redis.conf 检查 redis 启动情况 ps -ef | grep redis root 61020 1 0 02:14 ? 00:00:01 redis-server 127.0.0.1:7000 [cluster] root 61024 1 0 02:14 ? 00:00:01 redis-server 127.0.0.1:7001 [cluster] root 61029 1 0 02:14 ? 00:00:01 redis-server 127.0.0.1:7002 [cluster] netstat -tnlp | grep redis tcp 0 0 127.0.0.1:17000 0.0.0.0:* LISTEN 61020/redis-server tcp 0 0 127.0.0.1:17001 0.0.0.0:* LISTEN 61024/redis-server tcp 0 0 127.0.0.1:17002 0.0.0.0:* LISTEN 61029/redis-server tcp 0 0 127.0.0.1:7000 0.0.0.0:* LISTEN 61020/redis-server tcp 0 0 127.0.0.1:7001 0.0.0.0:* LISTEN 61024/redis-server tcp 0 0 127.0.0.1:7002 0.0.0.0:* LISTEN 61029/redis-server ##另外一台机器 ps -ef | grep redis root 9957 1 0 02:32 ? 00:00:01 redis-server 127.0.0.1:7003 [cluster] root 9964 1 0 02:32 ? 00:00:01 redis-server 127.0.0.1:7004 [cluster] root 9971 1 0 02:32 ? 00:00:01 redis-server 127.0.0.1:7005 [cluster] root 10065 4744 0 02:38 pts/0 00:00:00 grep --color=auto redis netstat -tlnp | grep redis tcp 0 0 127.0.0.1:17003 0.0.0.0:* LISTEN 9957/redis-server 1 tcp 0 0 127.0.0.1:17004 0.0.0.0:* LISTEN 9964/redis-server 1 tcp 0 0 127.0.0.1:17005 0.0.0.0:* LISTEN 9971/redis-server 1 tcp 0 0 127.0.0.1:7003 0.0.0.0:* LISTEN 9957/redis-server 1 tcp 0 0 127.0.0.1:7004 0.0.0.0:* LISTEN 9964/redis-server 1 tcp 0 0 127.0.0.1:7005 0.0.0.0:* LISTEN 9971/redis-server 1 创建集群 Redis 官方提供了 redis-trib.rb 这个工具，就在解压目录的 src 目录中，第三步中已将它复制到 /usr/local/bin 目录中，可以直接在命令行中使用了。使用下面这个命令即可完成安装。 redis-trib.rb create --replicas 1 192.168.31.245:7000 192.168.31.245:7001 192.168.31.245:7002 192.168.31.210:7003 192.168.31.210:7004 192.168.31.210:7005 其中，前三个 ip:port 为第一台机器的节点，剩下三个为第二台机器。 如果运行报下面错误， 是因为这个工具是用 ruby 实现的，所以需要安装 ruby。安装命令如下： yum -y install ruby ruby-devel rubygems rpm-build gem install redis 之后再运行 redis-trib.rb 命令，会出现如下提示： 输入 yes 即可，然后出现如下内容，说明安装成功。 　　 集群验证 在第一台机器上连接集群的7002端口的节点，在另外一台连接7005节点，连接方式为 redis-cli -h 192.168.31.245 -c -p 7002 ,加参数 -C 可连接到集群，因为上面 redis.conf 将 bind 改为了ip地址，所以 -h 参数不可以省略。 在7005节点执行命令 set hello world ，执行结果如下： 然后在另外一台7002端口，查看 key 为 hello 的内容， get hello ，执行结果如下： 说明集群运作正常。 简单说一下原理 redis cluster在设计的时候，就考虑到了去中心化，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。 Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的。redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点。 Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的salve 之间进行数据同步。当读取数据时，也根据一致性哈希算法到对应的 master 节点获取数据。只有当一个master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。 需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。 Docker搭建Redis集群 集群规划 ip 节点名称 角色 192.168.30.30 master sentinel 192.168.30.31 slave1 sentinel 192.168.30.32 slave2 sentinel redis集群搭建 在30上创建目录 /root/redis/conf /root/redis/data /root/redis/log 用来存放容器中的配置文件，持久化数据和日志 修改master节点redis.conf,从网上下载一份拷贝到/root/redis/conf修改，修改如下： A.注释掉IP绑定 #bind 127.0.0.1 B.端口设置为 port 6379 C.pidfile 为 pidfile /var/run/redis_6379.pid D.logfile \"/log/redis.log\" E.保护模式为no:protected-mode no Slave1修改如下 A.注释掉IP绑定 #bind 127.0.0.1 B.端口设置为 port 6380 C.pidfile 为 pidfile /var/run/redis_6380.pid D.logfile \"/log/redis.log\" E.保护模式为no:protected-mode no F.设置主服务器 replicaof 192.168.30.30 6379 Slave2修改如下 A.注释掉IP绑定 #bind 127.0.0.1 B.端口设置为 port 6381 C.pidfile 为 pidfile /var/run/redis_6381.pid D.logfile \"/log/redis.log\" E.保护模式为no:protected-mode no F.设置主服务器 replicaof 192.168.30.30 6379 在三台机器上分别执行容器运行命令 docker run -p 6379:6379 -v /root/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf -v /root/redis/data:/data -v /root/redis/log:/log -d --name redis-master --restart=always --network=host --privileged=true 106.54.126.251:5000/redis:5.0.4 redis-server /usr/local/etc/redis/redis.conf --appendonly yes docker run -p 6380:6380 -v /root/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf -v /root/redis/data:/data -v /root/redis/log:/log -d --name redis-slave1 --restart=always --network=host --privileged=true 106.54.126.251:5000/redis:5.0.4 redis-server /usr/local/etc/redis/redis.conf --appendonly yes docker run -p 6381:6381 -v /root/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf -v /root/redis/data:/data -v /root/redis/log:/log -d --name redis-slave2 --restart=always --network=host --privileged=true 106.54.126.251:5000/redis:5.0.4 redis-server /usr/local/etc/redis/redis.conf --appendonly yes sentinel集群搭建 修改master节点sentinel.conf,从网上下载一份拷贝到/root/redis/conf修改，修改如下： A.注释掉IP绑定 #bind 127.0.0.1 B.端口设置为 port 26379 C.修改监控主机ip：sentinel monitor mymaster 192.168.30.30 6379 2 D.logfile \"/log/sentinel.log\" E.注释保护模式为:protected-mode no Slave1修改如下 A.注释掉IP绑定 #bind 127.0.0.1 B.端口设置为 port 26380 C.修改监控主机ip：sentinel monitor mymaster 192.168.30.30 6379 2 D.logfile \"/log/sentinel.log\" E.注释保护模式为:protected-mode no Slave2修改如下 A.注释掉IP绑定 #bind 127.0.0.1 B.端口设置为 port 26381 C.修改监控主机ip：sentinel monitor mymaster 192.168.30.30 6379 2 D.logfile \"/log/sentinel.log\" E.注释保护模式为:protected-mode no 在三台机器上分别执行容器运行命令 docker run -it --name sentinel-01 -p 26379:26379 -v /root/redis/conf/sentinel.conf:/usr/local/etc/redis/sentinel.conf -v /root/redis/log:/log -d --restart=always --network=host --privileged 106.54.126.251:5000/redis:5.0.4 redis-sentinel /usr/local/etc/redis/sentinel.conf docker run -it --name sentinel-02 -p 26380:26380 -v /root/redis/conf/sentinel.conf:/usr/local/etc/redis/sentinel.conf -v /root/redis/log:/log -d --restart=always --network=host --privileged 106.54.126.251:5000/redis:5.0.4 redis-sentinel /usr/local/etc/redis/sentinel.conf docker run -it --name sentinel-03 -p 26381:26381 -v /root/redis/conf/sentinel.conf:/usr/local/etc/redis/sentinel.conf -v /root/redis/log:/log -d --restart=always --network=host --privileged 106.54.126.251:5000/redis:5.0.4 redis-sentinel /usr/local/etc/redis/sentinel.conf 到此，集群搭建完毕，可以停掉master,看会不会更换master节点 Redis日志的格式 In the log files the various log levels are represented as follows: . debug - verbose * notice # warning The log output for Redis 2.x will look something like this: [pid] date loglevel message For instance: [4018] 14 Nov 07:01:22.119 * Background saving terminated with success The possible values for role are as follows: X sentinel C RDB/AOF writing child S slave M master © vishon all right reserved，powered by GitbookUpdated at 2021-05-23 15:39:50 "},"k8s/k8s常用命令总结.html":{"url":"k8s/k8s常用命令总结.html","title":"k8s常用命令总结","keywords":"","body":"k8s常用命令 获取hostNetwork网络模式的deployment kubectl get deployment --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.hostNetwork==true)]} {\"namespace: \"} {.metadata.namespace}{\" name:\"} {.metadata.name} {\"\\n\"} {end}' 获取特权模式的deployment kubectl get deployment --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.containers[*].securityContext.privileged==true)]} {\"namespace: \"}{.metadata.namespace}{\"name:\"} {.metadata.name} {\"\\n\"} {end}' 获取控制进程可以获得超出其父进程的特权的deployment kubectl get deployment --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.containers[*].securityContext.allowPrivilegeEscalation==true)]} {\"namespace: \"}{.metadata.namespace}{\"name:\"} {.metadata.name} {\"\\n\"} {end}' 获取所有deployment的容器名称和namespace kubectl get deployment --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.containers[*])]} {\"namespace: \"}{.metadata.namespace}{\"name:\"} {.metadata.name} {\"\\n\"} {end}' 获取所有deployment的容器端口 kubectl get deployment --all-namespaces -o jsonpath='{range .items[*]} {\"namespace: \"}{.metadata.namespace}{\" name:\"} {.metadata.name} {\" \"}{.spec.template.spec.containers[*].ports} {\"\\n\"} {end}' 获取配置了hostport的deployment kubectl get deployment --all-namespaces -o jsonpath='{range .items[*]} {\"namespace: \"}{.metadata.namespace}{\" name:\"} {.metadata.name} {\" \"}{.spec.template.spec.containers[*].ports} {\"\\n\"} {end}' |grep map | grep hostPort | awk '{print $1 $2 \" \"$3 $4}' 获取配置了capabilities属性的deployment kubectl get deployment --all-namespaces -o jsonpath='{range .items[*]} {\"namespace: \"}{.metadata.namespace}{\" name:\"} {.metadata.name} {\" \"}{.spec.template.spec.containers[*].securityContext} {\"\\n\"} {end}' |grep capabilities | awk '{print $1 $2 \" \"$3 $4}' 获取所有配置了hostNetwork的DaemonSet kubectl get ds --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.hostNetwork==true)]} {\"namespace: \"} {.metadata.namespace}{\" name:\"} {.metadata.name} {\"\\n\"} {end}' 获取所有配置了hostIPC模式的DaemonSet kubectl get ds --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.hostIPC==true)]} {\"namespace: \"} {.metadata.namespace}{\" name:\"} {.metadata.name} {\"\\n\"} {end}' 获取所有配置了hostPID模式的DaemonSet kubectl get ds --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.hostPID==true)]} {\"namespace: \"} {.metadata.namespace}{\" name:\"} {.metadata.name} {\"\\n\"} {end}' 获取所有配置了allowPrivilegeEscalation模式的DaemonSet kubectl get ds --all-namespaces -o jsonpath='{range .items[?(@.spec.template.spec.containers[*].securityContext.allowPrivilegeEscalation==true)]} {\"namespace: \"}{.metadata.namespace}{\"name:\"} {.metadata.name} {\"\\n\"} {end}' 获取配置了hostport的DaemonSet kubectl get ds --all-namespaces -o jsonpath='{range .items[*]} {\"namespace: \"}{.metadata.namespace}{\" name:\"} {.metadata.name} {\" \"}{.spec.template.spec.containers[*].ports} {\"\\n\"} {end}' |grep map | grep hostPort | awk '{print $1 $2 \" \"$3 $4}' 获取所有pod的ip和所在node的ip kubectl get pods --all-namespaces -o=jsonpath='{range .items[*]}[nodeip:{.status.hostIP}, podip:{.status.podIP}]{\"\\n\"}{end}' © vishon all right reserved，powered by GitbookUpdated at 2021-05-21 17:07:57 "},"k8s/强制删除Terminating状态ns.html":{"url":"k8s/强制删除Terminating状态ns.html","title":"强制删除Terminating状态ns","keywords":"","body":"强制删除Terminating状态ns kubectl get ns 查看处于Terminating的ns [root@VM_1_4_centos ~]# kubectl get ns | grep testns testns Terminating 21d 将处于Terminating的ns的描述文件保存下来 [root@VM_1_4_centos ~]# kubectl get ns testns -o json > tmp.json [root@VM_1_4_centos ~]# cat tmp.json { \"apiVersion\": \"v1\", \"kind\": \"Namespace\", \"metadata\": { \"creationTimestamp\": \"2020-10-13T14:28:07Z\", \"name\": \"testns\", \"resourceVersion\": \"13782744400\", \"selfLink\": \"/api/v1/namespaces/testns\", \"uid\": \"9ff63d71-a4a1-43bc-89e3-78bf29788844\" }, \"spec\": { \"finalizers\": [ \"kubernetes\" ] }, \"status\": { \"phase\": \"Terminating\" } } 本地启动kube proxy kubectl proxy --port=8081 新开窗口执行删除操作 curl -k -H \"Content-Type: application/json\" -X PUT --data-binary @tmp.json http://127.0.0.1:8081/api/v1/namespaces 如果上面方法无法删除namespace，可以通过如下方法看下namespace是不是还有什么资源没有清理 若命名空间依然无法删除，则查询命名空间哪些资源 kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n 然后删除这些资源： $ kubectl -n p-4q9rv delete projectalertgroup.management.cattle.io/projectalert-workload-alert --grace-period=0 --force 若 Pod 还是无法删除，可以在 Pod 中添加补丁： kubectl -n p-4q9rv patch projectalertgroup.management.cattle.io/projectalert-workload-alert -p '{\"metadata\":{\"finalizers\":[]}}' --type='merge' 添加补丁后，强制删除： kubectl -n p-4q9rv delete projectalertrule.management.cattle.io/memory-close-to-resource-limited --grace-period=0 --force 然后执行下面命令删除namespace kubectl patch namespace -p '{\"metadata\":{\"finalizers\":[]}}' --type='merge' kubectl delete namespace cattle-system --grace-period=0 --force 其实也可以直接将修改对应ns生成json文件 [root@master-1 ~]# vim tmp.json 删除spec字段后，执行以下curl命令，使用kube-apiserver的8081端口，执行删除操作 #注意修改@XXX.json ，修改 namespaces/XXX/finalize ,其中XXX 表示你要删除的命名空间名称 [root@master-1 ~]# curl -k -H \"Content-Type: application/json\" -X PUT --data-binary @tmp.json http://127.0.0.1:8081/api/v1/namespaces/mysql/finalize © vishon all right reserved，powered by GitbookUpdated at 2021-05-21 11:46:56 "},"k8s/k8s中filebeat作为sidecar采集容器日志.html":{"url":"k8s/k8s中filebeat作为sidecar采集容器日志.html","title":"k8s中filebeat作为sidecar采集容器日志","keywords":"","body":"使用k8s的时候，会遇到一种情况就是需要单独采集下某个服务的日志进行过滤分析，这时候我们可以单独给服务部署一个filebeat的sidecar来采集过滤日志，下面我们来讲下如何部署 这里我们举例收集nginx服务的容器日志，直接部署下面的yaml文件即可 apiVersion: apps/v1 kind: Deployment metadata: name: nginx namespace: log spec: replicas: 2 selector: matchLabels: project: www app: nginx template: metadata: labels: project: www app: nginx spec: imagePullSecrets: - name: qcloudregistrykey containers: - name: nginx image: nginx ports: - containerPort: 80 name: web protocol: TCP resources: requests: cpu: 0.5 memory: 256Mi limits: cpu: 1 memory: 1Gi volumeMounts: - name: nginx-logs mountPath: /var/log/nginx - name: filebeat image: elastic/filebeat:7.3.1 args: [ \"-c\", \"/etc/filebeat.yml\", \"-e\", ] resources: limits: memory: 500Mi requests: cpu: 100m memory: 100Mi securityContext: runAsUser: 0 volumeMounts: - name: filebeat-config mountPath: /etc/filebeat.yml subPath: filebeat.yml - name: nginx-logs mountPath: /var/log/nginx volumes: - name: nginx-logs emptyDir: {} - name: filebeat-config configMap: name: filebeat-nginx-config --- apiVersion: v1 kind: ConfigMap metadata: name: filebeat-nginx-config namespace: log data: filebeat.yml: |- filebeat.inputs: - type: log paths: - /var/log/nginx/access.log # tags: [\"access\"] fields: app: www type: nginx-access fields_under_root: true setup.ilm.enabled: false setup.template.name: \"nginx-access\" setup.template.pattern: \"nginx-access-*\" output.elasticsearch: hosts: ['elasticsearch-master.log:9200'] index: \"nginx-access-%{+yyyy.MM.dd}\" 这里我们对上面的yaml进行说明下，我们将filebeat和nginx的/var/log/nginx目录挂载到emptyDir下，这样filebeat就可以直接读取到了nginx容器的日志目录，然后配置了一下filebeat的配置项，里面配置了日志采集的路径，以及输出的地址和索引名称，这里是直接收集到es里，当然你也可以投递到logstash和kafka logstash和kafka的配置参考如下 output.logstash: #logstash输出模块 enabled: true #启用模块 hosts: [\"localhost:5044\"] #logstash地址 worker: 1 #每个logstash的worker数？？？？？，默认1 compression_level: 3 #压缩级别，默认3 loadbalance: true #负载均衡开关，在不同的logstash间负载 pipelining: 0 #在处理新的批量期间，异步发送至logstash的批量次数？？？？？ index: 'filebeat' #可选配置，索引名称，默认为filebeat proxy_url: socks5://user:password@socks5-server:2233 #socks5代理服务器地址 proxy_use_local_resolver: false #使用代理时是否使用本地解析，默认false output.kafka: #kafka输出模块 output.redis: #redis输出模块 enabled: true #启用模块 hosts: [\"localhost:6379\"] #redis地址，地址为一个列表，如果loadbalance开启，则负载到里表中的服务器，当一个redis服务器不可达，事件将被分发到可到达的redis服务器 port: 6379 #redis端口，如果hosts内未包含端口信息，默认6379 key: filebeat #事件发布到redis的list或channel，默认filebeat password: #redis密码，默认无 db: 0 #redis的db值，默认0 datatype: list #发布事件使用的redis数据类型，如果为list，使用RPUSH命令（生产消费模式）。如果为channel，使用PUBLISH命令{发布订阅模式}。默认为list worker: 1 #为每个redis服务器启动的工作进程数，会根据负载均衡配置递增 loadbalance: true #负载均衡，默认开启 timeout: 5s #redis连接超时时间，默认5s max_retries: 3 #filebeat会忽略此设置，并一直重试到全部发送为止，其他beat设置为0即忽略，默认3次 bulk_max_size: 2048 ##对一个redis请求或管道批量的最大事件数，默认2048 proxy_url: #socks5代理地址，必须使用socks5:// proxy_use_local_resolver: false #使用代理时是否使用本地解析，默认false 因为我的es以及接到kibana里面了，这里我们试试在集群内访问下nginx服务的svc，在kibana是否能检索到日志 [root@VM-0-3-centos block]# for i in {1..100}; do curl http://172.16.90.29/; done 访问后，这里刷新下kibana，可以收到刚访问日志，我们访问了100次，这里也刚好收集100条 © vishon all right reserved，powered by GitbookUpdated at 2021-05-26 12:07:10 "},"tke/tke上使用docker-in-docker.html":{"url":"tke/tke上使用docker-in-docker.html","title":"tke上使用docker-in-docker","keywords":"","body":"这里我们讲一下如何在tke集群上部署docker in docker的pod，这里前提条件是集群的runtime需要用的是docker类型，如果是containerd是不行的。 apiVersion: apps/v1 kind: Deployment metadata: labels: k8s-app: docker-in-docker qcloud-app: docker-in-docker name: docker-in-docker namespace: tke-test spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: docker-in-docker qcloud-app: docker-in-docker strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 0 type: RollingUpdate template: metadata: creationTimestamp: null labels: k8s-app: docker-in-docker qcloud-app: docker-in-docker spec: containers: - command: - sleep - 70d image: docker:latest imagePullPolicy: Always name: docker-in-docker resources: limits: cpu: 500m memory: 1Gi requests: cpu: 250m memory: 256Mi securityContext: privileged: false terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/docker.sock name: vol subPath: docker.sock dnsPolicy: ClusterFirst imagePullSecrets: - name: qcloudregistrykey restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30 volumes: - hostPath: path: /var/run type: DirectoryOrCreate name: vol 这里我们用官方提供的docker in docker镜像，镜像默认是没有常驻进程，需要加上sleep命令起一个常驻进程，然后我们将节点的/var/run/docker.sock挂载容器内。 接下来我们进入容器就可以执行docker命令了 [root@VM-0-13-centos ~]# kubectl exec -it docker-in-docker-5b49479696-cm6gd -n tke-test /bin/sh / # docker version Client: Version: 20.10.6 API version: 1.40 Go version: go1.13.15 Git commit: 370c289 Built: Fri Apr 9 22:42:10 2021 OS/Arch: linux/amd64 Context: default Experimental: true Server: Docker Engine - Community Engine: Version: 19.03.9 API version: 1.40 (minimum version 1.12) Go version: go1.13.10 Git commit: 9d988398e7 Built: Fri May 15 00:28:17 2020 OS/Arch: linux/amd64 Experimental: false containerd: Version: v1.2.13 GitCommit: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc: Version: 1.0.0-rc10 GitCommit: dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init: Version: 0.18.0 GitCommit: fec3683 / # © vishon all right reserved，powered by GitbookUpdated at 2021-05-21 20:55:29 "},"tke/tke上部署Jumpserver.html":{"url":"tke/tke上部署Jumpserver.html","title":"tke上部署Jumpserver跳板机","keywords":"","body":"本篇文章主要讲述如何在tke集群上部署Jumpserver跳板机，本次采用的1.18.4版本的集群。 部署mysql数据库 这里我们通过helm部署mysql数据库 helm install nwx-mysql stable/mysql --namespace mysql 这里我们需要获取下mysql的root用户数据库密码 kubectl get secret nwx-mysql -n mysql -o jsonpath={.data.mysql-root-password} |base64 -d 注意这里还需要给Jumpserver创建好数据库，登录mysql执行下面这条sql create database jumpserver default charset 'utf8'; 部署redis数据库 redis数据库我们也通过helm部署下，也部署在mysql命名空间 helm install nwx-redis bitnami/redis --namespace mysql 然后获取下redis数据库的密码 kubectl get secret nwx-redis -n mysql -o jsonpath={.data.redis-password} |base64 -d 部署Jumpserver 这里我们先在控制台创建一个jumpserver-datadir的pvc，使用了20G的云硬盘 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: jumpserver-datadir namespace: jumpserver annotations: volume.beta.kubernetes.io/storage-provisioner: cloud.tencent.com/qcloud-cbs spec: accessModes: - ReadWriteOnce resources: requests: storage: 20Gi 然后生成下jumpserver需要到的SECRET_KEY和BOOTSTRAP_TOKEN # SECRET_KEY 生成方式： cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 50 # BOOTSTRAP_TOKEN生成方式： cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 16 apiVersion: apps/v1 kind: Deployment metadata: name: jumpserver namespace: jumpserver labels: app.kubernetes.io/instance: jumpserver app.kubernetes.io/name: jumpserver spec: replicas: 1 strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 0 type: RollingUpdate selector: matchLabels: app.kubernetes.io/instance: jumpserver app.kubernetes.io/name: jumpserver template: metadata: labels: app.kubernetes.io/instance: jumpserver app.kubernetes.io/name: jumpserver spec: containers: - env: - name: SECRET_KEY value: \"j9fKwmVV39DzqZ27tWnMffpLzP6TsvQkHCaxJRcKn\" - name: BOOTSTRAP_TOKEN value: \"nWZStpQ1UTO\" - name: DB_ENGINE value: \"mysql\" - name: DB_HOST value: \"nwx-mysql.mysql\" - name: DB_PORT value: \"3306\" - name: DB_USER value: \"root\" - name: \"DB_PASSWORD\" value: \"2hblVjr\" - name: DB_NAME value: \"jumpserver\" - name: REDIS_HOST value: \"nwx-redis-master.mysql\" - name: REDIS_PORT value: \"6379\" - name: REDIS_PASSWORD value: \"twsnty9\" image: jumpserver/jms_all:1.5.9 imagePullPolicy: IfNotPresent name: jumpserver ports: - containerPort: 80 name: http protocol: TCP - containerPort: 2222 name: ssh protocol: TCP volumeMounts: - mountPath: /opt/jumpserver/data/media name: datadir volumes: - name: datadir persistentVolumeClaim: claimName: jumpserver-datadir --- apiVersion: v1 kind: Service metadata: name: jumpserver namespace: jumpserver labels: app.kubernetes.io/instance: jumpserver app.kubernetes.io/name: jumpserver spec: ports: - name: http port: 80 targetPort: 80 protocol: TCP - name: ssh port: 2222 targetPort: 2222 protocol: TCP selector: app.kubernetes.io/instance: jumpserver app.kubernetes.io/name: jumpserver 创建ingress提供访问域名 apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: ingress name: jumpserver-ingress namespace: jumpserver spec: rules: - host: jumpserver.tke.niewx.cn http: paths: - backend: serviceName: jumpserver servicePort: 80 path: / 然后再控制台输入访问域名 ，jumpserver默认的登录密码是admin/admin © vishon all right reserved，powered by GitbookUpdated at 2021-05-23 12:16:29 "},"cloud/aws/awscli命令行操作.html":{"url":"cloud/aws/awscli命令行操作.html","title":"awscli命令行操作","keywords":"","body":"aws cli命令行操作 首先获取账号的access Access key ID,Secret access key AKIATRxxxxxxxxJX5WL,ZP2enHUH3XegoGhZxxxxxxxxfDMZo43ohz 登录ec2的实例下载awscli pip安装awscli ssh -i xxxxx.pem ec2-user@10.0.64.11 sudo -i yum -y install python-pip pip install awscli 2进制包安装awscli curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install 登录awscli [root@ip-10-0-64-11 ~]# aws configure AWS Access Key ID [None]: AKIATRMLTGCFIY5WRHGG AWS Secret Access Key [None]: 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 Default region name [None]: cn-northwest-1 Default output format [None]: 可以不输入 从S3桶下载对应的文件 aws s3 ls aws s3 cp s3://xxxx/jobs.tgz /root 其他的awscli命令 EC2 挂载 EBS linux 查看块设备： lsblk 格式化磁盘： sudo mkfs -t ext4 /dev/xvdb 挂载卷： sudo mount /dev/xvdb /mnt/mydir 卸载卷： sudo umount /dev/xvdb windows diskpart san policy=onlineall list disk disk yourdiskid attributes disk clear readonly online disk ec2操作 aws ec2 describe-instances aws ec2 describe-instances --instance-ids \"instanceid1\" \"instanceid2\" aws ec2 start-instances --instance-ids \"instanceid1\" \"instanceid2\" aws ec2 stop-intances --instance-ids \"instanceid1\" \"instanceid2\" aws ec2 run-instances --image-id ami-b6b62b8f --security-group-ids sg-xxxxxxxx --key-name mytestkey --block-device-mappings \"[{\\\"DeviceName\\\": \\\"/dev/sdh\\\",\\\"Ebs\\\":{\\\"VolumeSize\\\":100}}]\" --instance-type t2.medium --count 1 --subnet-id subnet-e8330c9c --associate-public-ip-address (Note: 若不指定subnet-id则会在默认vpc中去选，此时若指定了非默认vpc的安全组会出现请求错误。如无特殊要求，建议安全组和子网都不指定，就不会出现这种问题。) 查看region与AZ aws ec2 describe-region aws ec2 describe-availability-zones --region region-name 查看ami aws ec2 describe-images key-pair aws ec2 create-key-pair --key-name mykeyname 安全组 aws ec2 create-security-group --group-name mygroupname --description mydescription --vpc-id vpc-id (若不指定vpc，则在默认vpc中创建安全组) aws ec2 authorize-security-group-ingress --group-id sg-xxxxyyyy --protocol tcp --port 22 --cidr 0.0.0.0/0 aws ec2 authorize-security-group-ingress --group-id sg-xxxxyyyy --protocol tcp --port 9999 --source-group sg-xxxxxxxx AutoScaling 列出AS组 aws autoscaling describe-auto-scaling-groups 列出AS实例 aws autoscaling describe-auto-scaling-instances --instance-ids [instance-id-1 instance-id-2 ...] 从组中分离实例 aws autoscaling detach-instances --auto-scaling-group-name myasgroup --instance-ids instanceid1 instanceid2 [--should-decrement-desired-capacity|--no-should-decrement-desired-capacity] 附加实例到组 aws autoscaling attach-instances --auto-scaling-group-name myasgroup --instance-ids instanceid1 instanceid2 挂起AS流程 aws autoscaling suspend-process --auto-scaling-group-name myasgroup --scaling-processes AZRebalance|AlarmNotification|... 删除AS组 aws autoscaling delete-auto-scaling-group --auto-scaling-group-name myasgroup S3 查看 aws s3 ls aws s3 ls s3://bucket aws s3 ls s3://bucket/prefix 拷贝 aws s3 cp /to/local/path s3://bucket/prefix aws s3 cp s3://bucket/prefix /to/local/path aws s3 cp s3://bucket1/prefix1 s3://bucket2/prefix2 同步 aws sync [--delete] /to/local/dir s3://bucket/prefixdir aws sync [--delete] s3://bucket/prefixdir /to/local/dir aws sync [--delete] s3://bucket1/prefixdir1 s3://bucket2/prefixdir2 手动分片上传 文件分片 split -b 40m myfile myfile-part- 创建分片上传任务 aws s3api create-multipart-upload --bucket bucketname --key prefix 记录返回值 { \"Bucket\": \"bucketname\", \"UploadId\": \"uploadeid\", \"Key\": \"prefix\" } 上传分片 aws s3api upload-part --bucket bucketname --key prefix --part-number [分片上传编号(e.g. 1,2,3...)] --body myfile-[x] --upload-id uploadid 列出已上传分片，创建分片结构文件 aws s3api list-parts --bucket bucketname --key prefix --upload-id uploadid 将上命令结果中的parts部分保存为 temp 文件 {\"Parts\": [ { \"PartNumber\": 1, \"ETag\": \"\\\"xxxxxxx\\\"\" }, { \"PartNumber\": 2, \"ETag\": \"\\\"xxxxxxxx\\\"\" } ] } 结束分片上传任务 aws s3api complete-multipart-upload --multipart-upload file://temp --bucket bucketname --key prefix --upload-id uploadid AWSCLI访问阿里云OSS aws configure --p aliyun #设置key与secret,其他默认 aws configure set s3.addressing_style virtual --p aliyun aws s3 ls --endpoint-url [url/(e.g. http://oss-cn-hangzhou.aliyuncs.com)] --p aliyun IAM Role操作 aws iam create-role MY-ROLE-NAME --assum-role-policy-document file://path/to/trustpolicy.json aws iam put-role-policy --role-name MY-ROLE-NAME --policy-name MY-PERM-POLICY --policy-document file://path/to/permissionpolicy.json aws iam create-instance-profile --instance-profile-name MY-INSTANCE-PROFILE aws iam add-role-to-instance-profile --instance-profile-name MY-INSTANCE-PROFILE --role-name MY-ROLE-NAME AUTO-SCALING 查看信息 aws autoscaling describe-auto-scaling-groups aws autoscaling describe-auto-scaling-instances kinesis 创建流 aws kinesis create-stream –stream-name mystream –shard-count 列出流 aws kinesis list-streams 获取指定流的分片迭代器 aws kinesis get-shard-iterator –stream-name mystream –shard-id shard-1 –shard-iterator-type TRIM_HORIZON 发送数据到流 aws kinesis put-record –stream-name mystream –partition-key mykey –data test 获取流数据 aws kinesis get-records –shard-iterator myiterator © vishon all right reserved，powered by GitbookUpdated at 2021-05-22 11:05:01 "},"istio/istio中sidecar启动顺序问题.html":{"url":"istio/istio中sidecar启动顺序问题.html","title":"istio中sidecar启动顺序问题","keywords":"","body":"问题 当我们的一些服务往istio上迁移的时候，会出现一个问题，就是某些依赖数据库的服务会一直起不了，pod启动失败，这里排查原因是envoy容器还没起来，服务容器就起来了，导致业务流量无法被转发出去，从而连接数据库异常。 解决方案 这里解决问题的方案就是保证envoy这个sidecar容器先于业务容器启动，那么怎么保证sidecar容器先于业务容器启动呢？ istio1.7之后版本解决方案 istio1.7通过给istio-injector注入逻辑增加一个叫HoldApplicationUntilProxyStarts的开关来解决了该问题 添加了 values.global.proxy.holdApplicationUntilProxyStarts config选项，它使sidecar注入器在pod容器列表的开始处注入sidecar，并将其配置为阻止所有其他容器的开始，直到代理就绪为止。默认情况下禁用此选项。(#11130) 也就是说只要开启个这个特性，那么就可以保证pod里的sidecar容器内先于业务容器启动，这样就不会出现pod内容器启动顺序的问题 这里我们可以全局开启这个特性和单独给某个deployment开启这个特性 全局开启HoldApplicationUntilProxyStarts 全局开启只需要修改istiod的全局配置即可 kubectl edit cm -n istio-system istio-1-8-1 在defaultConfig字段下加上holdApplicationUntilProxyStarts: true apiVersion: v1 data: mesh: | accessLogEncoding: JSON accessLogFile: /dev/stdout accessLogFormat: \"\" defaultConfig: holdApplicationUntilProxyStarts: true discoveryAddress: istiod-1-8-1.istio-system.svc:15012 局部开启HoldApplicationUntilProxyStarts 如果单独给某个deployment开启这个特性，需要在pod的注解加上proxy.istio.io/config，将 holdApplicationUntilProxyStarts 置为 true apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: annotations: proxy.istio.io/config: | holdApplicationUntilProxyStarts: true labels: app: nginx spec: containers: - name: nginx image: \"nginx\" istio1.7版本之前的解决方案 如果是istio1.7之前的版本，是没有这个特性的，那么需要采用另外一种方案来解决这个问题，我们在业务容器启动前判断下envoy服务是否已经启动成功了 command: [\"/bin/bash\", \"-c\"] args: [\"while [[ \\\"$(curl -s -o /dev/null -w ''%{http_code}'' localhost:15020/healthz/ready)\\\" != '200' ]]; do echo Waiting for Sidecar;sleep 1; done; echo Sidecar available; start-app-cmd\"] 这里直接在deployment加上启动命令，如果探测envoy服务的15020端口返回200，则启动业务进程，这样可以保证sidecar先比业务容器启动 © vishon all right reserved，powered by GitbookUpdated at 2021-05-31 14:37:47 "}}